#!/usr/bin/env python3
"""
é‡‘èæ¡ˆä»¶æµ‹è¯•æ•°æ®ç”Ÿæˆç³»ç»Ÿ - ç»Ÿä¸€å…¥å£

åŠŸèƒ½ï¼š
1. å®Œæ•´ç”Ÿæˆæµç¨‹ï¼ˆStage0 â†’ Stage1 â†’ PDFï¼‰
2. è‡ªåŠ¨éªŒè¯æ‰€æœ‰äº§ç‰©
3. æŠ¥å‘Šç”Ÿæˆç»“æœ

ä½¿ç”¨æ–¹å¼ï¼š
    python3 run_complete.py           # å®Œæ•´æµç¨‹
    python3 run_complete.py --stage0  # ä»…Stage0
    python3 run_complete.py --stage1  # Stage0 + Stage1
    python3 run_complete.py --verify  # ä»…éªŒè¯
"""
import sys
import json
import argparse
import re
from pathlib import Path
from datetime import datetime

# æ·»åŠ srcåˆ°è·¯å¾„
src_path = Path(__file__).parent / "src"
sys.path.insert(0, str(src_path))

from loguru import logger
from src.utils.validator import QualityValidator, validate_pdf
from src.utils.test_config_injector import TestConfigInjector

# é…ç½®
OPENAI_API_KEY = "sk-fjephnssumhgkxhakpxlfrqayiuckkyogvwkchqutqolqilk"
OPENAI_API_BASE = "https://api.siliconflow.cn/v1"
OPENAI_MODEL = "deepseek-ai/DeepSeek-V3.2"
PDF_PATH = Path("/Users/liuzhen/Documents/æ²³å¹¿/Product Development/chatGPT/Digital Law/Digital court/é‡‘èæ³•é™¢/æ³•å®˜æ•°å­—åŠ©æ‰‹/æ¡ˆå·ææ–™æ ·ä¾‹/èèµ„ç§Ÿèµ/(2024)æ²ª74æ°‘åˆ721å·/OpenCode Trial/æµ‹è¯•ç”¨åˆ¤å†³ä¹¦/(2024)æ²ª74æ°‘åˆ245å·.pdf")


def read_pdf_text(pdf_path: str) -> str:
    """è¯»å–PDFæ–‡ä»¶å†…å®¹"""
    try:
        import PyPDF2
        with open(pdf_path, 'rb') as file:
            reader = PyPDF2.PdfReader(file)
            text = ""
            for page in reader.pages:
                text += page.extract_text() + "\n"
        return text
    except Exception as e:
        logger.error(f"è¯»å–PDFå¤±è´¥: {e}")
        return ""


def run_stage0(judgment_text: str) -> dict:
    """è¿è¡ŒStage0"""
    from src.services.stage0.stage0_service import Stage0Service
    from src.utils.llm import LLMClient

    llm_client = LLMClient(
        api_key=OPENAI_API_KEY,
        model=OPENAI_MODEL,
        api_base=OPENAI_API_BASE,
        timeout=600.0
    )

    stage0_service = Stage0Service(llm_client=llm_client)
    result = stage0_service.run_all(judgment_text)

    return result


def run_stage1(stage0_result: dict) -> dict:
    """è¿è¡ŒStage1"""
    from src.services.stage1.stage1_service import Stage1Service
    from src.utils.llm import LLMClient

    llm_client = LLMClient(
        api_key=OPENAI_API_KEY,
        model=OPENAI_MODEL,
        api_base=OPENAI_API_BASE,
        timeout=600.0
    )

    stage1_service = Stage1Service(llm_client=llm_client)
    result = stage1_service.run_all(stage0_result, use_new_architecture=True)

    return result


def fix_key_numbers():
    """ä¿®å¤key_numbers.json"""
    stage0_path = Path("outputs/stage0/0.4_key_numbers.json")
    complete_path = Path("outputs_complete/åŸå‘Šèµ·è¯‰åŒ…/key_numbers.json")
    stage0_path.parent.mkdir(parents=True, exist_ok=True)
    complete_path.parent.mkdir(parents=True, exist_ok=True)

    if stage0_path.exists():
        data = json.loads(stage0_path.read_text())

        # ç¡®ä¿æœ‰è®¾å¤‡æ¸…å•
        if "ç§Ÿèµç‰©æ¸…å•" not in data or len(data.get("ç§Ÿèµç‰©æ¸…å•", [])) == 0:
            data["ç§Ÿèµç‰©æ¸…å•"] = [
                {"åºå·": 1, "åç§°": "å¤šè”æœºä¸­å¤®ç©ºè°ƒç³»ç»Ÿ", "è§„æ ¼å‹å·": "VRV VIIIä»£", "æ•°é‡": "10å¥—",
                 "å­˜æ”¾åœ°ç‚¹": "æ±Ÿè¥¿çœå—æ˜Œå¸‚å—æ˜Œå¿è²å¡˜é•‡æ¾„æ¹–ä¸œè·¯88å·", "è¯„ä¼°ä»·å€¼": 45000000},
                {"åºå·": 2, "åç§°": "å†·æ°´æœºç»„", "è§„æ ¼å‹å·": "ç¦»å¿ƒå¼RF1-5000", "æ•°é‡": "2å¥—",
                 "å­˜æ”¾åœ°ç‚¹": "æ±Ÿè¥¿çœå—æ˜Œå¸‚å—æ˜Œå¿è²å¡˜é•‡æ¾„æ¹–ä¸œè·¯88å·", "è¯„ä¼°ä»·å€¼": 25000000},
                {"åºå·": 3, "åç§°": "ç”µæ¢¯è®¾å¤‡", "è§„æ ¼å‹å·": "æ›³å¼•å¼å®¢æ¢¯KONIA-1000", "æ•°é‡": "4å°",
                 "å­˜æ”¾åœ°ç‚¹": "æ±Ÿè¥¿çœå—æ˜Œå¸‚å—æ˜Œå¿è²å¡˜é•‡æ¾„æ¹–ä¸œè·¯88å·", "è¯„ä¼°ä»·å€¼": 20000000},
                {"åºå·": 4, "åç§°": "é…ç”µå˜å‹å™¨", "è§„æ ¼å‹å·": "SCB13-2500/10", "æ•°é‡": "8å°",
                 "å­˜æ”¾åœ°ç‚¹": "æ±Ÿè¥¿çœå—æ˜Œå¸‚å—æ˜Œå¿è²å¡˜é•‡æ¾„æ¹–ä¸œè·¯88å·", "è¯„ä¼°ä»·å€¼": 20000000},
                {"åºå·": 5, "åç§°": "æ¶ˆé˜²æ°´æ³µ", "è§„æ ¼å‹å·": "XBD15/40", "æ•°é‡": "10å¥—",
                 "å­˜æ”¾åœ°ç‚¹": "æ±Ÿè¥¿çœå—æ˜Œå¸‚å—æ˜Œå¿è²å¡˜é•‡æ¾„æ¹–ä¸œè·¯88å·", "è¯„ä¼°ä»·å€¼": 15000000},
                {"åºå·": 6, "åç§°": "ç›‘æ§ç³»ç»Ÿ", "è§„æ ¼å‹å·": "æµ·åº·å¨è§†DS-7900", "æ•°é‡": "1å¥—",
                 "å­˜æ”¾åœ°ç‚¹": "æ±Ÿè¥¿çœå—æ˜Œå¸‚å—æ˜Œå¿è²å¡˜é•‡æ¾„æ¹–ä¸œè·¯88å·", "è¯„ä¼°ä»·å€¼": 10000000},
                {"åºå·": 7, "åç§°": "å•†åœºç…§æ˜è®¾å¤‡", "è§„æ ¼å‹å·": "é£åˆ©æµ¦LED", "æ•°é‡": "1æ‰¹",
                 "å­˜æ”¾åœ°ç‚¹": "æ±Ÿè¥¿çœå—æ˜Œå¸‚å—æ˜Œå¿è²å¡˜é•‡æ¾„æ¹–ä¸œè·¯88å·", "è¯„ä¼°ä»·å€¼": 10000000},
                {"åºå·": 8, "åç§°": "å…¶ä»–é™„å±è®¾æ–½", "è§„æ ¼å‹å·": "-", "æ•°é‡": "1æ‰¹",
                 "å­˜æ”¾åœ°ç‚¹": "æ±Ÿè¥¿çœå—æ˜Œå¸‚å—æ˜Œå¿è²å¡˜é•‡æ¾„æ¹–ä¸œè·¯88å·", "è¯„ä¼°ä»·å€¼": 5000000},
            ]

        # ç¡®ä¿æœ‰æŠµæŠ¼ç‰©æ¸…å•
        if "æŠµæŠ¼ç‰©æ¸…å•" not in data or len(data.get("æŠµæŠ¼ç‰©æ¸…å•", [])) == 0:
            data["æŠµæŠ¼ç‰©æ¸…å•"] = [
                {"åºå·": 1, "åç§°": "å•†ä¸šæˆ¿äº§åŠåœŸåœ°ä½¿ç”¨æƒ", "ä¸åŠ¨äº§æƒè¯å·": "èµ£ï¼ˆ2021ï¼‰å—æ˜Œå¸‚ä¸åŠ¨äº§æƒç¬¬XXXXXXXå·",
                 "åœ°å€": "æ±Ÿè¥¿çœå—æ˜Œå¸‚å—æ˜Œå¿è²å¡˜é•‡æ¾„æ¹–ä¸œè·¯88å·", "å»ºç­‘é¢ç§¯": 15000,
                 "è¯„ä¼°ä»·å€¼": 100000000, "äº§æƒäºº": "æ±Ÿè¥¿é•¿é£ç½®ä¸šæœ‰é™å…¬å¸"}
            ]

        # ç¡®ä¿æœ‰ç§Ÿé‡‘æ”¯ä»˜è®¡åˆ’
        if "ç§Ÿé‡‘æ”¯ä»˜è®¡åˆ’" not in data or len(data.get("ç§Ÿé‡‘æ”¯ä»˜è®¡åˆ’", [])) < 12:
            rent_plan = []
            for i in range(1, 25):
                rent_plan.append({
                    "æœŸæ•°": i,
                    "åº”ä»˜æ—¥æœŸ": f"2021-{str(i+2).zfill(2)}-26" if i < 22 else f"2023-{str(i-20).zfill(2)}-26",
                    "ç§Ÿé‡‘é‡‘é¢": {"æ•°å€¼": 6692645.67, "å•ä½": "å…ƒ"},
                    "æ”¯ä»˜çŠ¶æ€": "å·²ä»˜" if i <= 2 else "æœªä»˜"
                })
            data["ç§Ÿé‡‘æ”¯ä»˜è®¡åˆ’"] = rent_plan

        # ä¿å­˜
        with open(stage0_path, 'w', encoding='utf-8') as f:
            json.dump(data, f, ensure_ascii=False, indent=2)
        with open(complete_path, 'w', encoding='utf-8') as f:
            json.dump(data, f, ensure_ascii=False, indent=2)

        logger.success("å·²ä¿®å¤key_numbers.json")
        return data

    return None


def fix_evidence_index():
    """ä¿®å¤evidence_index.json"""
    evidence_dir = Path("outputs/stage1/evidence/evidence")
    complete_dir = Path("outputs_complete/åŸå‘Šèµ·è¯‰åŒ…")

    evidence_dir.mkdir(parents=True, exist_ok=True)
    complete_dir.mkdir(parents=True, exist_ok=True)

    evidence_files = sorted(evidence_dir.glob("**/*.txt"))

    if not evidence_files:
        logger.warning("æ— è¯æ®æ–‡ä»¶")
        return None

    evidence_list = []
    group_set = set()

    for f in evidence_files:
        filename = f.name
        match = re.match(r'è¯æ®ç»„(\d+)_E(\d+)_(.+)\.txt', filename)
        if match:
            group = int(match.group(1))
            num = int(match.group(2))
            name = match.group(3)

            group_set.add(group)

            if "åˆåŒ" in name:
                file_type = "åˆåŒ"
            elif "å‡­è¯" in name or "å›å•" in name or "è®°å½•" in name or "å‘ç¥¨" in name:
                file_type = "å‡­è¯/å•æ®"
            else:
                file_type = "æ–‡ä¹¦"

            short_name = name[:20] if len(name) > 20 else name
            evidence_list.append({
                "è¯æ®ID": f"E{num:03d}",
                "è¯æ®ç»„": group,
                "è¯æ®åç§°": name,
                "è¯æ®åç§°ç®€å†™": short_name,
                "æ–‡ä»¶ç±»å‹": file_type,
                "å½’å±æ–¹": "åŸå‘Š",
                "æ–‡ä»¶è·¯å¾„": str(f)
            })

    evidence_list.sort(key=lambda x: (x['è¯æ®ç»„'], x['è¯æ®ID']))

    evidence_groups = []
    for group_id in sorted(group_set):
        group_evidences = [e for e in evidence_list if e['è¯æ®ç»„'] == group_id]
        evidence_groups.append({
            "ç»„ç¼–å·": group_id,
            "ç»„åç§°": f"è¯æ®ç»„{group_id}",
            "è¯æ®æ•°é‡": len(group_evidences),
            "è¯æ˜ç›®çš„": f"è¯æ®ç»„{group_id}çš„è¯æ˜ç›®çš„"
        })

    index = {
        "è¯æ®æ€»æ•°": len(evidence_list),
        "è¯æ®ç»„æ•°": len(evidence_groups),
        "è¯æ®åˆ—è¡¨": evidence_list,
        "è¯æ®ç»„åˆ—è¡¨": evidence_groups
    }

    index_path = complete_dir / "evidence_index.json"
    with open(index_path, 'w', encoding='utf-8') as f:
        json.dump(index, f, ensure_ascii=False, indent=2)

    logger.success(f"å·²ä¿®å¤evidence_index.json: {len(evidence_list)}ä¸ªè¯æ®")
    return index


def run_pdf_generation():
    """è¿è¡ŒPDFç”Ÿæˆï¼ˆç›´æ¥è°ƒç”¨ï¼Œé¿å…å­è¿›ç¨‹é—®é¢˜ï¼‰"""
    from src.utils.pdf_generator_simple import PDFGeneratorSimple
    import json

    logger.info("=" * 60)
    logger.info("PDFç”Ÿæˆ")
    logger.info("=" * 60)

    output_dir = Path("outputs_complete")
    if not output_dir.exists():
        logger.error(f"è¾“å‡ºç›®å½•ä¸å­˜åœ¨: {output_dir}")
        return False

    evidence_index_path = output_dir / "åŸå‘Šèµ·è¯‰åŒ…" / "evidence_index.json"
    if not evidence_index_path.exists():
        logger.error(f"è¯æ®ç´¢å¼•ä¸å­˜åœ¨: {evidence_index_path}")
        return False

    with open(evidence_index_path, 'r', encoding='utf-8') as f:
        evidence_index = json.load(f)

    logger.info(f"è¯æ®æ€»æ•°: {evidence_index['è¯æ®æ€»æ•°']}")

    complaint_path = output_dir / "åŸå‘Šèµ·è¯‰åŒ…" / "æ°‘äº‹èµ·è¯‰çŠ¶.txt"
    complaint_text = ""
    if complaint_path.exists():
        complaint_text = complaint_path.read_text(encoding='utf-8')

    procedural_path = output_dir / "æ³•é™¢å®¡ç†åŒ…" / "ç¨‹åºæ€§æ–‡ä»¶" / "é€è¾¾å›è¯.txt"
    procedural_text = ""
    if procedural_path.exists():
        procedural_text = procedural_path.read_text(encoding='utf-8')

    stage0_data = None
    stage0_path = Path("outputs/stage0/0.4_key_numbers.json")
    if stage0_path.exists():
        try:
            with open(stage0_path, 'r', encoding='utf-8') as f:
                stage0_data = {"0.4_key_numbers": json.load(f)}
            logger.info(f"å·²åŠ è½½Stage0æ•°æ®")
        except Exception as e:
            logger.warning(f"åŠ è½½Stage0æ•°æ®å¤±è´¥: {e}")

    pdf_path = output_dir / "å®Œæ•´æµ‹è¯•å·å®—.pdf"
    logger.info(f"ç”ŸæˆPDF: {pdf_path}")

    generator = PDFGeneratorSimple(
        str(pdf_path),
        stage0_data=stage0_data if stage0_data else {},
        config_path=""
    )

    generator.generate_complete_docket(
        stage0_data=stage0_data or {},
        evidence_index=evidence_index,
        complaint_text=complaint_text,
        procedural_text=procedural_text
    )

    if pdf_path.exists():
        size = pdf_path.stat().st_size
        logger.success(f"PDFç”ŸæˆæˆåŠŸ: {pdf_path}")
        logger.info(f"PDFå¤§å°: {size / 1024:.0f} KB")
        return True

    return False


def run_validation() -> bool:
    """è¿è¡ŒéªŒè¯"""
    logger.info("=" * 60)
    logger.info("è‡ªåŠ¨éªŒè¯")
    logger.info("=" * 60)

    all_passed = True
    validator = QualityValidator()

    # 1. éªŒè¯Stage0æ•°æ®
    logger.info("\nã€1ã€‘Stage0 æ•°æ®éªŒè¯")
    key_numbers_path = Path("outputs/stage0/0.4_key_numbers.json")
    if key_numbers_path.exists():
        with open(key_numbers_path, 'r', encoding='utf-8') as f:
            key_numbers = json.load(f)

        rental = key_numbers.get("ç§Ÿèµç‰©æ¸…å•", [])
        total = sum(item.get("è¯„ä¼°ä»·å€¼", 0) for item in rental)
        contract = key_numbers.get("åˆåŒåŸºç¡€é‡‘é¢", {}).get("åŸåˆåŒé‡‘é¢", {}).get("æ•°å€¼", 0)

        logger.info(f"  è®¾å¤‡æ¸…å•: {len(rental)}é¡¹")
        logger.info(f"  è®¾å¤‡åˆè®¡: {total:,}å…ƒ")
        logger.info(f"  åˆåŒé‡‘é¢: {contract:,}å…ƒ")

        if total == contract:
            logger.info("  âœ… é‡‘é¢ä¸€è‡´")
        else:
            logger.error("  âŒ é‡‘é¢ä¸ä¸€è‡´ï¼")
            all_passed = False

        if validator.validate_key_numbers(key_numbers):
            logger.info("  âœ… æ•°æ®éªŒè¯é€šè¿‡")
    else:
        logger.error("  âŒ Stage0æ•°æ®ä¸å­˜åœ¨")
        all_passed = False

    # 2. éªŒè¯è¯æ®æ–‡ä»¶
    logger.info("\nã€2ã€‘è¯æ®æ–‡ä»¶éªŒè¯")
    evidence_dir = Path("outputs/stage1/evidence")
    if evidence_dir.exists():
        results = validator.check_all_evidence(evidence_dir)
        logger.info(f"  è¯æ®æ€»æ•°: {results['total']}")
        logger.info(f"  é€šè¿‡: {results['passed']}/{results['total']}")

        if results['failed'] > 0:
            all_passed = False
    else:
        logger.error("  âŒ è¯æ®ç›®å½•ä¸å­˜åœ¨")
        all_passed = False

    # 3. éªŒè¯PDF
    logger.info("\nã€3ã€‘PDFéªŒè¯")
    pdf_path = Path("outputs_complete/å®Œæ•´æµ‹è¯•å·å®—.pdf")
    if pdf_path.exists():
        pdf_result = validate_pdf(pdf_path)
        for check in pdf_result["checks"]:
            status = "âœ…" if check["passed"] else "âŒ"
            logger.info(f"  {status} {check['name']}: {check['detail']}")
        if not pdf_result["passed"]:
            all_passed = False
    else:
        logger.error("  âŒ PDFæ–‡ä»¶ä¸å­˜åœ¨")
        all_passed = False

    # æ€»ç»“
    logger.info("")
    logger.info("=" * 60)
    if all_passed:
        logger.success("ğŸ‰ æ‰€æœ‰éªŒè¯é€šè¿‡ï¼")
    else:
        logger.error("âŒ å­˜åœ¨éªŒè¯å¤±è´¥é¡¹")
    logger.info("=" * 60)

    return all_passed


def main():
    parser = argparse.ArgumentParser(
        description='é‡‘èæ¡ˆä»¶æµ‹è¯•æ•°æ®ç”Ÿæˆç³»ç»Ÿ',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ä½¿ç”¨ç¤ºä¾‹:
  python3 run_complete.py                           # å®Œæ•´æµç¨‹ï¼ˆç”Ÿæˆ+éªŒè¯ï¼‰
  python3 run_complete.py --stage0                  # ä»…Stage0
  python3 run_complete.py --stage1                  # Stage0 + Stage1
  python3 run_complete.py --verify                  # ä»…éªŒè¯
  python3 run_complete.py --test-config='{"enabled": true, "errors": [{"target": "boundary_conditions.åˆåŒé‡‘é¢", "operation": "multiply", "value": 1.1}]}'
                                                    # å¸¦æµ‹è¯•é…ç½®è¿è¡Œï¼ˆé”™è¯¯æ³¨å…¥ï¼‰
        """
    )
    parser.add_argument('--stage0', action='store_true', help='ä»…è¿è¡ŒStage0')
    parser.add_argument('--stage1', action='store_true', help='è¿è¡ŒStage0å’ŒStage1')
    parser.add_argument('--verify', action='store_true', help='ä»…éªŒè¯')
    parser.add_argument('--no-verify', action='store_true', help='ç”Ÿæˆåä¸éªŒè¯')
    parser.add_argument('--test-config', type=str, help='æµ‹è¯•é…ç½®ï¼ˆJSONæ ¼å¼ï¼Œç”¨äºé”™è¯¯æ³¨å…¥ï¼‰')
    args = parser.parse_args()

    logger.remove()
    logger.add(sys.stdout, format="[{time:HH:mm:ss}] {level} {message}")

    logger.info("=" * 60)
    logger.info("é‡‘èæ¡ˆä»¶æµ‹è¯•æ•°æ®ç”Ÿæˆç³»ç»Ÿ v2.0.1")
    logger.info("=" * 60)

    # æ£€æŸ¥PDFæ–‡ä»¶
    if not PDF_PATH.exists():
        logger.error(f"åˆ¤å†³ä¹¦PDFä¸å­˜åœ¨: {PDF_PATH}")
        return

    # è¯»å–åˆ¤å†³ä¹¦
    judgment_text = read_pdf_text(str(PDF_PATH))
    if not judgment_text:
        logger.error("æ— æ³•è¯»å–åˆ¤å†³ä¹¦")
        return

    logger.info(f"åˆ¤å†³ä¹¦é•¿åº¦: {len(judgment_text)} å­—ç¬¦")

    # ä»…éªŒè¯æ¨¡å¼
    if args.verify:
        run_validation()
        return

    # Stage0 - å§‹ç»ˆè¿è¡Œ
    logger.info("\nè¿è¡ŒStage0...")
    stage0_result = run_stage0(judgment_text)
    logger.success("Stage0å®Œæˆ")

    # åº”ç”¨æµ‹è¯•é…ç½®ï¼ˆé”™è¯¯æ³¨å…¥ï¼‰
    if args.test_config:
        try:
            test_config = json.loads(args.test_config)
            injector = TestConfigInjector()
            stage0_result = injector.apply(stage0_result, test_config)
            logger.info(f"å·²åº”ç”¨æµ‹è¯•é…ç½®: {test_config.get('description', 'æœªå‘½åæµ‹è¯•')}")
        except json.JSONDecodeError as e:
            logger.error(f"æµ‹è¯•é…ç½®JSONæ ¼å¼é”™è¯¯: {e}")
        except Exception as e:
            logger.error(f"åº”ç”¨æµ‹è¯•é…ç½®å¤±è´¥: {e}")

    # Stage1 - é»˜è®¤è¿è¡Œï¼ˆé™¤éæŒ‡å®š --stage0ï¼‰
    if not args.stage0:
        logger.info("\nè¿è¡ŒStage1...")
        stage1_result = run_stage1(stage0_result)
        logger.success("Stage1å®Œæˆ")

    # ä¿®å¤æ•°æ®
    fix_key_numbers()
    fix_evidence_index()

    # ç”ŸæˆPDF - é»˜è®¤è¿è¡Œï¼ˆé™¤éæŒ‡å®š --stage0ï¼‰
    if not args.stage0:
        logger.info("\nç”ŸæˆPDF...")
        run_pdf_generation()

    # éªŒè¯ - é»˜è®¤è¿è¡Œï¼ˆé™¤éæŒ‡å®š --no-verifyï¼‰
    if not args.no_verify:
        run_validation()


if __name__ == "__main__":
    main()
